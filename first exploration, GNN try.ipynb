{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-27T06:53:02.407852Z",
     "start_time": "2025-09-27T06:53:01.999790Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "from itertools import combinations\n",
    "import itertools\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "\n",
    "from scipy.stats import mannwhitneyu\n",
    "\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.tools.sm_exceptions import ConvergenceWarning\n",
    "import warnings\n",
    "\n",
    "import networkx as nx\n",
    "from matplotlib.lines import Line2D\n",
    "import math\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Loading Raw Data",
   "id": "438e5fbb69609b15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:53:03.719498Z",
     "start_time": "2025-09-27T06:53:03.704030Z"
    }
   },
   "cell_type": "code",
   "source": "ia_A_path = \"full/ia_A.csv\"",
   "id": "e54999c87f88f7ac",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:53:30.196746Z",
     "start_time": "2025-09-27T06:53:04.140053Z"
    }
   },
   "cell_type": "code",
   "source": "df_A = pd.read_csv(ia_A_path)",
   "id": "f80651675f56a57f",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Selecting Relevant and Separating Reading Regimes",
   "id": "e9b6bd12e87fb581"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:53:40.694569Z",
     "start_time": "2025-09-27T06:53:34.062726Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_A_filtered = df_A[(df_A['repeated_reading_trial'] == False) & ((df_A['practice_trial'] == False))]\n",
    "\n",
    "article_col='article_id'\n",
    "difficulty_col='difficulty_level'\n",
    "batch_col='article_batch'\n",
    "paragraph_col='paragraph_id'\n",
    "\n",
    "df_A_filtered['text_id'] = (\n",
    "    df_A_filtered[article_col].astype(str) + '_' +\n",
    "    df_A_filtered[difficulty_col].astype(str) + '_' +\n",
    "    df_A_filtered[batch_col].astype(str) + '_' +\n",
    "    df_A_filtered[paragraph_col].astype(str)\n",
    ")\n",
    "\n",
    "df_A_hunters = df_A_filtered[df_A_filtered['question_preview'] == True].copy()\n",
    "df_A_gatherers = df_A_filtered[df_A_filtered['question_preview'] == False].copy()"
   ],
   "id": "8d445f30191c409",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deeth\\AppData\\Local\\Temp\\ipykernel_31172\\1320471520.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_A_filtered['text_id'] = (\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Generating Basic By Row Features",
   "id": "bf74867b7c201591"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:53:40.756943Z",
     "start_time": "2025-09-27T06:53:40.743410Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_correct_answer(df):\n",
    "    df = df.copy()\n",
    "    df['is_correct'] = (df['selected_answer_position'] == df['correct_answer_position']).astype(int)\n",
    "    return df"
   ],
   "id": "96c688d3e65bcc24",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:53:40.834564Z",
     "start_time": "2025-09-27T06:53:40.821342Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_answers_texts(df):\n",
    "    df = df.copy()\n",
    "    def get_answer_by_char(row, char):\n",
    "        answer_idx = eval(row[\"answers_order\"]).index(char)\n",
    "        return row[f\"answer_{answer_idx + 1}\"]\n",
    "\n",
    "    df[\"answer_A\"] = df.apply(\n",
    "        lambda row: get_answer_by_char(row, \"A\"), axis=1\n",
    "    )\n",
    "    df[\"answer_B\"] = df.apply(\n",
    "        lambda row: get_answer_by_char(row, \"B\"), axis=1\n",
    "    )\n",
    "    df[\"answer_C\"] = df.apply(\n",
    "        lambda row: get_answer_by_char(row, \"C\"), axis=1\n",
    "    )\n",
    "    df[\"answer_D\"] = df.apply(\n",
    "        lambda row: get_answer_by_char(row, \"D\"), axis=1\n",
    "    )\n",
    "    return df"
   ],
   "id": "13ecfd9c0c7397f5",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:53:40.880797Z",
     "start_time": "2025-09-27T06:53:40.866235Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_area_screen_loc(df):\n",
    "    df = df.copy()\n",
    "    for col in ['question', 'answer_1', 'answer_2', 'answer_3', 'answer_4']:\n",
    "        df[col] = df[col].fillna('').astype(str)\n",
    "\n",
    "    df['question_tokens'] = df['question'].str.split()\n",
    "    df['1_tokens'] = df['answer_1'].str.split()\n",
    "    df['2_tokens'] = df['answer_2'].str.split()\n",
    "    df['3_tokens'] = df['answer_3'].str.split()\n",
    "    df['4_tokens'] = df['answer_4'].str.split()\n",
    "\n",
    "    df['question_len'] = df['question_tokens'].apply(len)\n",
    "    df['1_len'] = df['1_tokens'].apply(len)\n",
    "    df['2_len'] = df['2_tokens'].apply(len)\n",
    "    df['3_len'] = df['3_tokens'].apply(len)\n",
    "    df['4_len'] = df['4_tokens'].apply(len)\n",
    "\n",
    "    def assign_area(group):\n",
    "        q_len = group['question_len'].iloc[0]\n",
    "        first_len = group['1_len'].iloc[0]\n",
    "        second_len = group['2_len'].iloc[0]\n",
    "        third_len = group['3_len'].iloc[0]\n",
    "        fourth_len = group['4_len'].iloc[0]\n",
    "\n",
    "        q_end = q_len - 1\n",
    "        first_end = q_len + first_len - 1\n",
    "        second_end = q_len + first_len + second_len - 1\n",
    "        third_end = q_len + first_len + second_len + third_len - 1\n",
    "        fourth_end = q_len + first_len + second_len + third_len + fourth_len\n",
    "\n",
    "        index_id = group['IA_ID'] - 1\n",
    "\n",
    "        conditions = [\n",
    "            (index_id <= q_end),\n",
    "            (index_id > q_end) & (index_id <= first_end),\n",
    "            (index_id > first_end) & (index_id <= second_end),\n",
    "            (index_id > second_end) & (index_id <= third_end),\n",
    "            (index_id > third_end) & (index_id <= fourth_end)\n",
    "        ]\n",
    "\n",
    "        choices = ['question', 'answer_0', 'answer_1', 'answer_2', 'answer_3']\n",
    "        group['area_screen_loc'] = np.select(conditions, choices, default='unknown')\n",
    "        return group\n",
    "\n",
    "    df_area_split = df.set_index(['TRIAL_INDEX', 'participant_id']).groupby(['TRIAL_INDEX', 'participant_id'], group_keys=False).apply(assign_area)\n",
    "    return df_area_split"
   ],
   "id": "f46f4a49c1fe1b9b",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:53:40.926953Z",
     "start_time": "2025-09-27T06:53:40.913138Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_area_label(df):\n",
    "    def get_screen_loc(row):\n",
    "        if row['area_screen_loc'] == 'question':\n",
    "            return 'question'\n",
    "        elif row['area_screen_loc'].startswith('answer_'):\n",
    "            answers_order = ast.literal_eval(row['answers_order'])\n",
    "            idx = int(row['area_screen_loc'].split('_')[1])\n",
    "            return f'answer_{answers_order[idx]}'\n",
    "        return None\n",
    "\n",
    "    df['area_label'] = df.apply(get_screen_loc, axis=1)\n",
    "    return df"
   ],
   "id": "652e124eade064bd",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:53:40.973197Z",
     "start_time": "2025-09-27T06:53:40.961254Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_selected_answer_label(df):\n",
    "    df = df.copy()\n",
    "    df['answers_order'] = df['answers_order'].apply(ast.literal_eval)\n",
    "    df['selected_answer_label'] = df.apply(lambda row: row['answers_order'][row['selected_answer_position']], axis=1)\n",
    "    return df"
   ],
   "id": "fc9c60d2a730d5f8",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.116078Z",
     "start_time": "2025-09-27T06:53:41.004697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_dataframe(df, functions):\n",
    "    for func in functions:\n",
    "        print(func)\n",
    "        df = func(df)\n",
    "    return df.reset_index()\n",
    "\n",
    "processing_functions = [\n",
    "    create_correct_answer,\n",
    "    create_answers_texts,\n",
    "    create_area_screen_loc,\n",
    "    create_area_label,\n",
    "\n",
    "    create_selected_answer_label,\n",
    "]\n",
    "\n",
    "df_base_features_h = process_dataframe(df_A_hunters, processing_functions)\n",
    "df_base_features_g = process_dataframe(df_A_gatherers, processing_functions)"
   ],
   "id": "725e8548cc4c9f5e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function create_correct_answer at 0x0000014D1A261310>\n",
      "<function create_answers_texts at 0x0000014D1A261C10>\n",
      "<function create_area_screen_loc at 0x0000014D1A261F70>\n",
      "<function create_area_label at 0x0000014D1A261040>\n",
      "<function create_selected_answer_label at 0x0000014D1A261CA0>\n",
      "<function create_correct_answer at 0x0000014D1A261310>\n",
      "<function create_answers_texts at 0x0000014D1A261C10>\n",
      "<function create_area_screen_loc at 0x0000014D1A261F70>\n",
      "<function create_area_label at 0x0000014D1A261040>\n",
      "<function create_selected_answer_label at 0x0000014D1A261CA0>\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Specialised Groupings Features Generators",
   "id": "4b347faa2147727d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.209010Z",
     "start_time": "2025-09-27T06:56:18.193565Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_mean_area_dwell_time(df):\n",
    "    return df.groupby(['TRIAL_INDEX', 'participant_id','area_label'], as_index=False).agg(mean_dwell_time=(\"IA_DWELL_TIME\", \"mean\"))"
   ],
   "id": "ae36218dd0f30e1e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.225959Z",
     "start_time": "2025-09-27T06:56:18.212297Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_mean_area_fix_count(df):\n",
    "    return df.groupby(['TRIAL_INDEX', 'participant_id','area_label'], as_index=False).agg(mean_fixations_count=(\"IA_FIXATION_COUNT\", \"mean\"))"
   ],
   "id": "eacb7efd532a3b83",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.273049Z",
     "start_time": "2025-09-27T06:56:18.258200Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_mean_first_fix_duration(df):\n",
    "    df['IA_FIRST_FIXATION_DURATION_INT'] = df[\"IA_FIRST_FIXATION_DURATION\"].replace('.', 0).astype(int)\n",
    "    return df.groupby(['TRIAL_INDEX', 'participant_id','area_label'], as_index=False).agg(mean_first_fixation_duration=(\"IA_FIRST_FIXATION_DURATION_INT\", \"mean\"))"
   ],
   "id": "cd8cdc681698b4f2",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.318827Z",
     "start_time": "2025-09-27T06:56:18.304579Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_skip_rate(df):\n",
    "    df['AREA_SKIPPED'] = (df['IA_DWELL_TIME'] == 0).astype(int)\n",
    "    return df.groupby(['TRIAL_INDEX', 'participant_id','area_label'], as_index=False).agg(skip_rate=(\"AREA_SKIPPED\", \"mean\"))"
   ],
   "id": "49581a22cb29e258",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.372999Z",
     "start_time": "2025-09-27T06:56:18.359753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_dwell_proportions(df):\n",
    "    aggregated_df = (\n",
    "        df.groupby(['participant_id', 'TRIAL_INDEX', 'area_label'], as_index=False)\n",
    "        .agg({'IA_DWELL_TIME': 'sum'})\n",
    "        .rename(columns={'IA_DWELL_TIME': 'total_area_dwell_time'})\n",
    "    )\n",
    "\n",
    "    aggregated_df['total_dwell_time'] = aggregated_df.groupby(['participant_id', 'TRIAL_INDEX'])['total_area_dwell_time'].transform('sum')\n",
    "\n",
    "    aggregated_df['area_dwell_proportion'] = aggregated_df['total_area_dwell_time'] / aggregated_df['total_dwell_time']\n",
    "    aggregated_df = aggregated_df.fillna(0)\n",
    "\n",
    "    return aggregated_df"
   ],
   "id": "cc610ee30547ebee",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.419478Z",
     "start_time": "2025-09-27T06:56:18.405076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_last_area_and_location_visited(df):\n",
    "    df['IA_LAST_FIXATION_TIME_INT'] = df[\"IA_LAST_FIXATION_TIME\"].replace('.', 0).astype(int)\n",
    "    df_sorted = df.sort_values(by=['participant_id', 'TRIAL_INDEX', 'IA_LAST_FIXATION_TIME_INT'], ascending=[True, True, False])\n",
    "    top_fixations = df_sorted.groupby(['participant_id', 'TRIAL_INDEX']).head(5)\n",
    "\n",
    "    last_area = (\n",
    "        top_fixations.groupby(['participant_id', 'TRIAL_INDEX'])['area_label']\n",
    "        .agg(lambda x: x.value_counts().idxmax())\n",
    "        .reset_index()\n",
    "        .rename(columns={'area_label': 'last_area_visited'})\n",
    "    )\n",
    "\n",
    "    last_location = (\n",
    "        top_fixations.groupby(['participant_id', 'TRIAL_INDEX'])['area_screen_loc']\n",
    "        .agg(lambda x: x.value_counts().idxmax())\n",
    "        .reset_index()\n",
    "        .rename(columns={'area_screen_loc': 'last_location_visited'})\n",
    "    )\n",
    "\n",
    "    result = pd.merge(last_area, last_location, on=['participant_id', 'TRIAL_INDEX'])\n",
    "\n",
    "    return result"
   ],
   "id": "322eaaa0a09c2d24",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.465932Z",
     "start_time": "2025-09-27T06:56:18.451555Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_fixation_sequence_tags(df):\n",
    "    result = []\n",
    "    for (trial_index, participant_id), group in df.groupby(['TRIAL_INDEX', 'participant_id']):\n",
    "        group_ids = set(group['IA_ID'].unique())\n",
    "\n",
    "        id_to_label = dict(zip(group['IA_ID'], group['area_label']))\n",
    "        id_to_location = dict(zip(group['IA_ID'], group['area_screen_loc']))\n",
    "\n",
    "        sequence_str = group['INTEREST_AREA_FIXATION_SEQUENCE'].iloc[0]\n",
    "        sequence = eval(sequence_str)\n",
    "\n",
    "        label_sequence = []\n",
    "        location_sequence = []\n",
    "\n",
    "        for ia_id in sequence:\n",
    "            if ia_id in group_ids:\n",
    "                label_sequence.append(id_to_label[ia_id])\n",
    "                location_sequence.append(id_to_location[ia_id])\n",
    "        result.append({\n",
    "            'TRIAL_INDEX': trial_index,\n",
    "            'participant_id': participant_id,\n",
    "            'fix_by_label': label_sequence[1:],\n",
    "            'fix_by_loc': location_sequence[1:]\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(result)\n",
    "\n"
   ],
   "id": "777e2bbd30597310",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.511502Z",
     "start_time": "2025-09-27T06:56:18.497546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_simplified_fixation_tags(df):\n",
    "    result = []\n",
    "    for (trial_index, participant_id), group in df.groupby(['TRIAL_INDEX', 'participant_id']):\n",
    "        group_ids = set(group['IA_ID'].unique())\n",
    "\n",
    "        id_to_label = dict(zip(group['IA_ID'], group['area_label']))\n",
    "        id_to_location = dict(zip(group['IA_ID'], group['area_screen_loc']))\n",
    "\n",
    "        sequence_str = group['INTEREST_AREA_FIXATION_SEQUENCE'].iloc[0]\n",
    "        sequence = eval(sequence_str)\n",
    "\n",
    "        valid_fixations = []\n",
    "        for ia_id in sequence:\n",
    "            if ia_id in group_ids:\n",
    "                valid_fixations.append((\n",
    "                    ia_id,\n",
    "                    id_to_label[ia_id],\n",
    "                    id_to_location[ia_id],\n",
    "                ))\n",
    "\n",
    "        simpl_labels    = []\n",
    "        simpl_locations = []\n",
    "\n",
    "        for label, run in itertools.groupby(valid_fixations, key=lambda item: item[1]):\n",
    "            run_list = list(run)\n",
    "            simpl_labels.append(label)\n",
    "            simpl_locations.append(run_list[0][2])\n",
    "\n",
    "        result.append({\n",
    "            'TRIAL_INDEX':       trial_index,\n",
    "            'participant_id':    participant_id,\n",
    "            'simpl_fix_by_label':    tuple(simpl_labels[:]),\n",
    "            'simpl_fix_by_loc':      tuple(simpl_locations[:]),\n",
    "        })\n",
    "    return pd.DataFrame(result)"
   ],
   "id": "ebd5c2532434c3b5",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.558456Z",
     "start_time": "2025-09-27T06:56:18.544005Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def first_visits_ordered(df):\n",
    "#     df = df.copy()\n",
    "#\n",
    "#     result = []\n",
    "#     for (trial_index, participant_id), group in df.groupby(['TRIAL_INDEX', 'participant_id']):\n",
    "#         seen = set()\n",
    "#         label_seq = []\n",
    "#         loc_seq = []\n",
    "#         for labels, screen_locs in zip(group['fix_by_label'], group['fix_by_loc']):\n",
    "#             for label, screen_loc in zip(labels, screen_locs):\n",
    "#                 if (label, screen_loc) not in seen:\n",
    "#                     seen.add((label, screen_loc))\n",
    "#                     label_seq.append(label)\n",
    "#                     loc_seq.append(screen_loc)\n",
    "#         label_seq = tuple(label_seq)\n",
    "#         loc_seq = tuple(loc_seq)\n",
    "#         result.append({\n",
    "#             'TRIAL_INDEX': trial_index,\n",
    "#             'participant_id': participant_id,\n",
    "#             'first_visits_area_label': label_seq,\n",
    "#             'first_visits_area_screen_loc': loc_seq\n",
    "#         })\n",
    "#     df_first_visits = pd.DataFrame(result)\n",
    "#     return df_first_visits"
   ],
   "id": "88c254c706a482dd",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.605519Z",
     "start_time": "2025-09-27T06:56:18.591437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def last_visits_ordered(df):\n",
    "#     df = df.copy()\n",
    "#\n",
    "#     result = []\n",
    "#     for (trial_index, participant_id), group in df.groupby(['TRIAL_INDEX', 'participant_id']):\n",
    "#         seen = set()\n",
    "#         label_seq = []\n",
    "#         loc_seq = []\n",
    "#         for labels, screen_locs in zip(group.iloc[::-1]['fix_by_label'], group.iloc[::-1]['fix_by_loc']):\n",
    "#             i = 0\n",
    "#             for label, screen_loc in zip(reversed(labels), reversed(screen_locs)):\n",
    "#                 i = i +1\n",
    "#                 if (label, screen_loc) not in seen:\n",
    "#                     seen.add((label, screen_loc))\n",
    "#                     label_seq.append(label)\n",
    "#                     loc_seq.append(screen_loc)\n",
    "#         label_seq = tuple(label_seq[::-1])\n",
    "#         loc_seq = tuple(loc_seq[::-1])\n",
    "#         result.append({\n",
    "#             'TRIAL_INDEX': trial_index,\n",
    "#             'participant_id': participant_id,\n",
    "#             'last_visits_area_label': label_seq,\n",
    "#             'last_visits_area_screen_loc': loc_seq\n",
    "#         })\n",
    "#     df_first_visits = pd.DataFrame(result)\n",
    "#     return df_first_visits"
   ],
   "id": "feafd270b2e56aa6",
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.651013Z",
     "start_time": "2025-09-27T06:56:18.636548Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def first_4_visits(df, num_of_visits = 4):\n",
    "#     df = df.copy()\n",
    "#\n",
    "#     result = []\n",
    "#     for (trial_index, participant_id), group in df.groupby(['TRIAL_INDEX', 'participant_id']):\n",
    "#         label_seq = []\n",
    "#         loc_seq = []\n",
    "#\n",
    "#         for labels, screen_locs in zip(group['simpl_fix_by_label'], group['simpl_fix_by_loc']):\n",
    "#             for label, screen_loc in zip(labels, screen_locs):\n",
    "#                 if label == 'question':\n",
    "#                     continue\n",
    "#                 if len(label_seq) < num_of_visits:\n",
    "#                     label_seq.append(label)\n",
    "#                     loc_seq.append(screen_loc)\n",
    "#                 else:\n",
    "#                     break\n",
    "#             if len(label_seq) >= num_of_visits:\n",
    "#                 break\n",
    "#\n",
    "#         result.append({\n",
    "#             'TRIAL_INDEX': trial_index,\n",
    "#             'participant_id': participant_id,\n",
    "#             'first_visits_area_label': tuple(label_seq),\n",
    "#             'first_visits_area_screen_loc': tuple(loc_seq)\n",
    "#         })\n",
    "#\n",
    "#     return pd.DataFrame(result)\n"
   ],
   "id": "e3d19bce07db5bbb",
   "outputs": [],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.697654Z",
     "start_time": "2025-09-27T06:56:18.684270Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def last_4_visits(df, num_of_visits = 4):\n",
    "#     df = df.copy()\n",
    "#\n",
    "#     result = []\n",
    "#     for (trial_index, participant_id), group in df.groupby(['TRIAL_INDEX', 'participant_id']):\n",
    "#         all_labels = []\n",
    "#         all_locs = []\n",
    "#\n",
    "#         for labels, screen_locs in zip(group['simpl_fix_by_label'], group['simpl_fix_by_loc']):\n",
    "#             for label, screen_loc in zip(labels, screen_locs):\n",
    "#                 if label != 'question':\n",
    "#                     all_labels.append(label)\n",
    "#                     all_locs.append(screen_loc)\n",
    "#\n",
    "#         label_seq = tuple(all_labels[-num_of_visits:])\n",
    "#         loc_seq = tuple(all_locs[-num_of_visits:])\n",
    "#\n",
    "#         result.append({\n",
    "#             'TRIAL_INDEX': trial_index,\n",
    "#             'participant_id': participant_id,\n",
    "#             'last_visits_area_label': label_seq,\n",
    "#             'last_visits_area_screen_loc': loc_seq\n",
    "#         })\n",
    "#\n",
    "#     return pd.DataFrame(result)\n"
   ],
   "id": "f00e7163403314cb",
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Feature Generation",
   "id": "2adf57b089296ce2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.746991Z",
     "start_time": "2025-09-27T06:56:18.730532Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def generate_new_row_features(functions, df, default_join_columns=['TRIAL_INDEX', 'participant_id', 'area_label']):\n",
    "    result_df = df.copy()\n",
    "\n",
    "    for func_tuple in functions:\n",
    "        func, func_kwargs = func_tuple\n",
    "        print(func)\n",
    "\n",
    "        join_columns = func_kwargs.get('join_columns', default_join_columns)\n",
    "\n",
    "        new_features_df = func(result_df)\n",
    "        result_df = result_df.merge(new_features_df, on=join_columns, how='left')\n",
    "\n",
    "    return result_df"
   ],
   "id": "44607f4933352633",
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:18.793627Z",
     "start_time": "2025-09-27T06:56:18.779568Z"
    }
   },
   "cell_type": "code",
   "source": [
    "per_row_feature_generators = [\n",
    "    (create_mean_area_dwell_time, {}),\n",
    "    (create_mean_area_fix_count, {}),\n",
    "    (create_mean_first_fix_duration, {}),\n",
    "    (create_skip_rate, {}),\n",
    "    (create_dwell_proportions, {}),\n",
    "    (create_last_area_and_location_visited, {'join_columns': ['TRIAL_INDEX', 'participant_id']}),\n",
    "    (create_fixation_sequence_tags, {'join_columns': ['TRIAL_INDEX', 'participant_id']}),\n",
    "    (create_simplified_fixation_tags, {'join_columns': ['TRIAL_INDEX', 'participant_id']}),\n",
    "    # (first_4_visits, {'join_columns': ['TRIAL_INDEX', 'participant_id']}),\n",
    "    # (last_4_visits, {'join_columns': ['TRIAL_INDEX', 'participant_id']}),\n",
    "    #(first_visits_ordered, {'join_columns': ['TRIAL_INDEX', 'participant_id']}),\n",
    "    #(last_visits_ordered, {'join_columns': ['TRIAL_INDEX', 'participant_id']}),\n",
    "\n",
    "\n",
    "]"
   ],
   "id": "cf3ddbe8ab91f131",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:48.339873Z",
     "start_time": "2025-09-27T06:56:18.827310Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_with_features_h = generate_new_row_features(per_row_feature_generators, df_base_features_h)\n",
    "df_with_features_g = generate_new_row_features(per_row_feature_generators, df_base_features_g)"
   ],
   "id": "6892f7dcecfe10e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function create_mean_area_dwell_time at 0x0000014F98850B80>\n",
      "<function create_mean_area_fix_count at 0x0000014F988508B0>\n",
      "<function create_mean_first_fix_duration at 0x0000014F98850280>\n",
      "<function create_skip_rate at 0x0000014F988509D0>\n",
      "<function create_dwell_proportions at 0x0000014F98850550>\n",
      "<function create_last_area_and_location_visited at 0x0000014F98850AF0>\n",
      "<function create_fixation_sequence_tags at 0x0000014F98305790>\n",
      "<function create_simplified_fixation_tags at 0x0000014F98850430>\n",
      "<function create_mean_area_dwell_time at 0x0000014F98850B80>\n",
      "<function create_mean_area_fix_count at 0x0000014F988508B0>\n",
      "<function create_mean_first_fix_duration at 0x0000014F98850280>\n",
      "<function create_skip_rate at 0x0000014F988509D0>\n",
      "<function create_dwell_proportions at 0x0000014F98850550>\n",
      "<function create_last_area_and_location_visited at 0x0000014F98850AF0>\n",
      "<function create_fixation_sequence_tags at 0x0000014F98305790>\n",
      "<function create_simplified_fixation_tags at 0x0000014F98850430>\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:48.401815Z",
     "start_time": "2025-09-27T06:56:48.387692Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_first_and_last(df, num=4):\n",
    "    df = df.copy()\n",
    "\n",
    "    def prep(seq, remove_questions):\n",
    "        if remove_questions:\n",
    "            seq = [x for x in seq if x != 'question']\n",
    "        return seq\n",
    "\n",
    "    for remove_q, suffix, take_num in [\n",
    "        (True, \"\", num),\n",
    "        (False, \"_with_q\", num + 1)\n",
    "    ]:\n",
    "        df[f'first_visits_area_screen_loc{suffix}'] = (\n",
    "            df['simpl_fix_by_loc'].apply(lambda s: tuple(prep(s, remove_q)[:take_num]))\n",
    "        )\n",
    "        df[f'first_visits_area_label{suffix}'] = (\n",
    "            df['simpl_fix_by_label'].apply(lambda s: tuple(prep(s, remove_q)[:take_num]))\n",
    "        )\n",
    "\n",
    "        # Last N\n",
    "        df[f'last_visits_area_screen_loc{suffix}'] = (\n",
    "            df['simpl_fix_by_loc'].apply(lambda s: tuple(prep(s, remove_q)[-take_num:]))\n",
    "        )\n",
    "        df[f'last_visits_area_label{suffix}'] = (\n",
    "            df['simpl_fix_by_label'].apply(lambda s: tuple(prep(s, remove_q)[-take_num:]))\n",
    "        )\n",
    "\n",
    "    return df\n"
   ],
   "id": "55e68e99a0ec3f32",
   "outputs": [],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:56:53.801059Z",
     "start_time": "2025-09-27T06:56:48.449389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_with_features_h = add_first_and_last(df_with_features_h)\n",
    "df_with_features_g = add_first_and_last(df_with_features_g)"
   ],
   "id": "ba44ea5c21f603f4",
   "outputs": [],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:57:25.848050Z",
     "start_time": "2025-09-27T06:56:53.850164Z"
    }
   },
   "cell_type": "code",
   "source": "df_with_features_h.to_csv('df_with_features_h.csv')",
   "id": "686aa9865021cfe4",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-27T06:57:58.058264Z",
     "start_time": "2025-09-27T06:57:25.895327Z"
    }
   },
   "cell_type": "code",
   "source": "df_with_features_g.to_csv('df_with_features_g.csv')",
   "id": "324484b5c9a77753",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Visualisations",
   "id": "143d4dc2e3d01d80"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Boxplots and U-Tests",
   "id": "3106667bb9a946a1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_boxplot(dataframe, x_column, y_column, hue_column, plt_title=\"Boxplot\", h_or_g = 'hunters'):\n",
    "    dataframe = dataframe[['TRIAL_INDEX','participant_id', x_column, y_column, hue_column]].drop_duplicates().copy()\n",
    "    plt.figure(figsize=(12,6))\n",
    "    sns.boxplot(\n",
    "        data=dataframe,\n",
    "        x=x_column,\n",
    "        y=y_column,\n",
    "        hue=hue_column,\n",
    "        showfliers=False\n",
    "    )\n",
    "    plt.title(plt_title)\n",
    "    plt.xlabel(x_column)\n",
    "    plt.ylabel(y_column)\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.tight_layout()\n",
    "    plt.legend(title=hue_column)\n",
    "    plt.savefig(f\"plots/boxplots/boxplot_{x_column}_{y_column}_{h_or_g}.png\")\n",
    "    plt.show()\n"
   ],
   "id": "f116348965068fcb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "# text_id = article_id + difficulty_level + paragraph_id + article_batch",
   "id": "8748ff41ad76cbf2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_metric_stat_mixed(dataframe,\n",
    "                              label_column,\n",
    "                              stat_column,\n",
    "                              correct_column='is_correct',\n",
    "                              article_col='article_id',\n",
    "                              difficulty_col='difficulty_level',\n",
    "                              batch_col='article_batch',\n",
    "                              paragraph_col='paragraph_id',\n",
    "                              participant_col='participant_id'):\n",
    "\n",
    "\n",
    "    dataframe = dataframe[['TRIAL_INDEX', participant_col, label_column, stat_column, correct_column,\n",
    "                           article_col,difficulty_col,batch_col,paragraph_col ]].drop_duplicates().copy()\n",
    "    dataframe['text_id'] = dataframe.apply(\n",
    "        lambda row: f\"{row[article_col]}_{row[difficulty_col]}_{row[batch_col]}_{row[paragraph_col]}\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    categories = dataframe[label_column].unique()\n",
    "    results = []\n",
    "\n",
    "    valid_participants = (\n",
    "        dataframe.groupby(participant_col)[correct_column]\n",
    "                 .nunique()\n",
    "                 .pipe(lambda s: s[s == 2].index)\n",
    "    )\n",
    "    df_filtered = dataframe[dataframe[participant_col].isin(valid_participants)]\n",
    "\n",
    "    for category in categories:\n",
    "        category_data = df_filtered[df_filtered[label_column] == category].copy()\n",
    "\n",
    "        correct_data = category_data[category_data[correct_column] == 1]\n",
    "        incorrect_data = category_data[category_data[correct_column] == 0]\n",
    "\n",
    "        if len(correct_data) == 0 or len(incorrect_data) == 0:\n",
    "            continue\n",
    "\n",
    "        median_correct = correct_data[stat_column].median()\n",
    "        median_incorrect = incorrect_data[stat_column].median()\n",
    "        mean_correct = correct_data[stat_column].mean()\n",
    "        mean_incorrect = incorrect_data[stat_column].mean()\n",
    "\n",
    "        formula = f\"{stat_column} ~ {correct_column}\"\n",
    "\n",
    "        model = smf.mixedlm(\n",
    "            formula,\n",
    "            data=category_data,\n",
    "            groups=category_data[participant_col],\n",
    "            re_formula=\"~1\",\n",
    "            vc_formula={\"text_id\": \"0 + C(text_id)\"}\n",
    "        )\n",
    "        fit_result = model.fit()\n",
    "        param_name = correct_column\n",
    "\n",
    "        if param_name in fit_result.params.index:\n",
    "            coef = fit_result.params[param_name]\n",
    "            pval = fit_result.pvalues[param_name]\n",
    "        else:\n",
    "            coef = np.nan\n",
    "            pval = np.nan\n",
    "\n",
    "        results.append({\n",
    "            label_column: category,\n",
    "            \"coef_correct\": coef,\n",
    "            \"p_value_correct\": pval,\n",
    "            \"median_correct\": median_correct,\n",
    "            \"median_incorrect\": median_incorrect,\n",
    "            \"mean_correct\": mean_correct,\n",
    "            \"mean_incorrect\": mean_incorrect\n",
    "        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df = results_df.sort_values(by=\"p_value_correct\")\n",
    "    return results_df\n"
   ],
   "id": "13ee9b959f5d888",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def metric_analysis(metric):\n",
    "    print(\"HUNTERS BOXPLOTS:\")\n",
    "    plot_boxplot(df_with_features_h, 'area_label', metric, 'is_correct', plt_title=f'{metric} by label (hunters)', h_or_g = 'hunters')\n",
    "    plot_boxplot(df_with_features_h, 'area_screen_loc', metric, 'is_correct', plt_title=f'{metric} by location (hunters)', h_or_g = 'hunters')\n",
    "\n",
    "    print(\"GATHERERS BOXPLOTS:\")\n",
    "    plot_boxplot(df_with_features_g, 'area_label', metric, 'is_correct', plt_title=f'{metric} by label (gatherers)', h_or_g = 'gatherers')\n",
    "    plot_boxplot(df_with_features_g, 'area_screen_loc', metric, 'is_correct', plt_title=f'{metric} by location (gatherers)', h_or_g = 'gatherers')\n",
    "\n",
    "    # print(\"HUNTERS TESTS:\")\n",
    "    # print(analyze_metric_stat_mixed(\n",
    "    #     dataframe=df_with_features_h,\n",
    "    #     label_column='area_label',\n",
    "    #     stat_column=metric,\n",
    "    #     correct_column='is_correct',\n",
    "    #     article_col='article_id',\n",
    "    #     difficulty_col='difficulty_level',\n",
    "    #     batch_col='article_batch',\n",
    "    #     paragraph_col='paragraph_id',\n",
    "    #     participant_col='participant_id'\n",
    "    # ))\n",
    "    # print(analyze_metric_stat_mixed(\n",
    "    #     dataframe=df_with_features_h,\n",
    "    #     label_column='area_screen_loc',\n",
    "    #     stat_column=metric,\n",
    "    #     correct_column='is_correct',\n",
    "    #     article_col='article_id',\n",
    "    #     difficulty_col='difficulty_level',\n",
    "    #     batch_col='article_batch',\n",
    "    #     paragraph_col='paragraph_id',\n",
    "    #     participant_col='participant_id'\n",
    "    # ))\n",
    "    # print(\"GATHERERS TESTS:\")\n",
    "    # print(analyze_metric_stat_mixed(\n",
    "    #     dataframe=df_with_features_g,\n",
    "    #     label_column='area_label',\n",
    "    #     stat_column=metric,\n",
    "    #     correct_column='is_correct',\n",
    "    #     article_col='article_id',\n",
    "    #     difficulty_col='difficulty_level',\n",
    "    #     batch_col='article_batch',\n",
    "    #     paragraph_col='paragraph_id',\n",
    "    #     participant_col='participant_id'\n",
    "    # ))\n",
    "    # print(analyze_metric_stat_mixed(\n",
    "    #     dataframe=df_with_features_g,\n",
    "    #     label_column='area_screen_loc',\n",
    "    #     stat_column=metric,\n",
    "    #     correct_column='is_correct',\n",
    "    #     article_col='article_id',\n",
    "    #     difficulty_col='difficulty_level',\n",
    "    #     batch_col='article_batch',\n",
    "    #     paragraph_col='paragraph_id',\n",
    "    #     participant_col='participant_id'\n",
    "    # ))\n"
   ],
   "id": "38ca7f744b5b16df",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"statsmodels\")\n",
    "warnings.filterwarnings(\"ignore\", category=ConvergenceWarning, module=\"statsmodels\")\n",
    "\n",
    "# metric_analysis('mean_dwell_time')\n",
    "# metric_analysis('mean_fixations_count')\n",
    "# metric_analysis('mean_first_fixation_duration')\n",
    "metric_analysis('skip_rate')\n",
    "# metric_analysis('area_dwell_proportion')"
   ],
   "id": "b94ec3d8ab9b0a8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def analyze_group_differences(dataframe, label_column, stat_column, correct_column='is_correct'):\n",
    "    results = []\n",
    "\n",
    "    for is_correct_value in dataframe[correct_column].unique():\n",
    "        subset_df = dataframe[dataframe[correct_column] == is_correct_value]\n",
    "        categories = subset_df[label_column].unique()\n",
    "\n",
    "        for cat1, cat2 in combinations(categories, 2):\n",
    "            group1 = subset_df[subset_df[label_column] == cat1][stat_column]\n",
    "            group2 = subset_df[subset_df[label_column] == cat2][stat_column]\n",
    "\n",
    "            if len(group1) == 0 or len(group2) == 0:\n",
    "                continue\n",
    "\n",
    "            mannwhitney_result = mannwhitneyu(group1, group2, alternative='two-sided')\n",
    "\n",
    "            results.append({\n",
    "                'is_correct': is_correct_value,\n",
    "                'group1': cat1,\n",
    "                'group2': cat2,\n",
    "                'U_statistic': mannwhitney_result.statistic,\n",
    "                'p_value': mannwhitney_result.pvalue,\n",
    "                'median_group1': group1.median(),\n",
    "                'median_group2': group2.median(),\n",
    "                'mean_group1': group1.mean(),\n",
    "                'mean_group2': group2.mean()\n",
    "            })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    return results_df.sort_values(['is_correct', 'p_value'])"
   ],
   "id": "de64b14e2a3f8f6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# analyze_group_differences(df_with_features_h, label_column='area_label', stat_column='mean_dwell_time')\n",
    "# analyze_group_differences(df_with_features_h, label_column='area_screen_loc', stat_column='mean_dwell_time')\n",
    "#\n",
    "# analyze_group_differences(df_with_features_h, label_column='area_label', stat_column='mean_fixations_count')\n",
    "# analyze_group_differences(df_with_features_h, label_column='area_screen_loc', stat_column='mean_fixations_count')\n",
    "#\n",
    "# analyze_group_differences(df_with_features_h, label_column='area_label', stat_column='mean_first_fixation_duration')\n",
    "# analyze_group_differences(df_with_features_h, label_column='area_screen_loc', stat_column='mean_first_fixation_duration')\n",
    "#\n",
    "# analyze_group_differences(df_with_features_h, label_column='area_label', stat_column='skip_rate')\n",
    "# analyze_group_differences(df_with_features_h, label_column='area_screen_loc', stat_column='skip_rate')\n",
    "#\n",
    "# analyze_group_differences(df_with_features_h, label_column='area_label', stat_column='area_dwell_proportion')\n",
    "# analyze_group_differences(df_with_features_h, label_column='area_screen_loc', stat_column='area_dwell_proportion')"
   ],
   "id": "7c58190a8fde76fe",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Matrix Plots",
   "id": "d7985f74e2ba1432"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def matrix_plot(df, stat, correct = 1, h_or_g = 'hunters'):\n",
    "    df = df[['TRIAL_INDEX', 'participant_id', 'area_label', 'area_screen_loc', stat]].drop_duplicates().copy()\n",
    "    matrix = pd.pivot_table(\n",
    "        data=df,\n",
    "        index='area_label',\n",
    "        columns='area_screen_loc',\n",
    "        values=stat,\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "\n",
    "    ax = sns.heatmap(\n",
    "    matrix,\n",
    "    annot=True,\n",
    "    cmap='Blues',\n",
    "    fmt=\".2f\",\n",
    "    cbar_kws={'label': f'{stat}'}\n",
    "    )\n",
    "    if correct == 1:\n",
    "        plt.title(f\"{stat} of correct answers\")\n",
    "    else:\n",
    "        plt.title(f\"{stat} of incorrect answers\")\n",
    "    plt.xlabel('area_screen_loc')\n",
    "    plt.ylabel(\"area_label\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"plots/matrix_plots/matrix_{stat}_{correct}_{h_or_g}.png\")\n",
    "    plt.show()\n"
   ],
   "id": "1026cfd86cd2d1c6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def matrix_plot_ABCD(df, stat, selected = 'A', h_or_g = 'hunters'):\n",
    "    df = df[['TRIAL_INDEX', 'participant_id', 'area_label', 'area_screen_loc', stat]].drop_duplicates().copy()\n",
    "    matrix = pd.pivot_table(\n",
    "        data=df,\n",
    "        index='area_label',\n",
    "        columns='area_screen_loc',\n",
    "        values=stat,\n",
    "        aggfunc='mean'\n",
    "    )\n",
    "\n",
    "    sns.heatmap(\n",
    "    matrix,\n",
    "    annot=True,\n",
    "    cmap='Blues',\n",
    "    fmt=\".2f\",\n",
    "    cbar_kws={'label': f'{stat}'}\n",
    "    )\n",
    "\n",
    "    plt.title(f\"{stat} of those who chose {selected} \")\n",
    "    plt.xlabel('area_screen_loc')\n",
    "    plt.ylabel(\"area_label\")\n",
    "    plt.tight_layout()\n",
    "    #plt.savefig(f\"new_plots/basic_stats/{h_or_g}_{stat}_{selected}.png\")\n",
    "    #plt.savefig(f\"plots/matrix_plots/{stat}_{selected}_{h_or_g}.png\")\n",
    "\n",
    "    plt.show()"
   ],
   "id": "c8603ddb35806f59",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def label_vs_loc_mat(metric, dfh, dfg):\n",
    "    print(\"HUNTERS\")\n",
    "    matrix_plot_ABCD(dfh[dfh['selected_answer_label'] == 'A'], metric, selected='A', h_or_g = 'hunters')\n",
    "    matrix_plot_ABCD(dfh[dfh['selected_answer_label'] == 'B'], metric, selected='B', h_or_g = 'hunters')\n",
    "    matrix_plot_ABCD(dfh[dfh['selected_answer_label'] == 'C'], metric, selected='C', h_or_g = 'hunters')\n",
    "    matrix_plot_ABCD(dfh[dfh['selected_answer_label'] == 'D'], metric, selected='D', h_or_g = 'hunters')\n",
    "\n",
    "    print(\"GATHERERS\")\n",
    "    matrix_plot_ABCD(dfg[dfg['selected_answer_label'] == 'A'], metric, selected='A', h_or_g = 'gatherers')\n",
    "    matrix_plot_ABCD(dfg[dfg['selected_answer_label'] == 'B'], metric, selected='B', h_or_g = 'gatherers')\n",
    "    matrix_plot_ABCD(dfg[dfg['selected_answer_label'] == 'C'], metric, selected='C', h_or_g = 'gatherers')\n",
    "    matrix_plot_ABCD(dfg[dfg['selected_answer_label'] == 'D'], metric, selected='D', h_or_g = 'gatherers')"
   ],
   "id": "52580b74ee80c896",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_noq_h = df_with_features_h[df_with_features_h['area_label'] != 'question']\n",
    "df_noq_g = df_with_features_g[df_with_features_g['area_label'] != 'question']"
   ],
   "id": "42962561455cadec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "label_vs_loc_mat('mean_dwell_time', df_noq_h, df_noq_g)\n",
    "# label_vs_loc_mat('mean_fixations_count', df_noq_h, df_noq_g)\n",
    "# label_vs_loc_mat('mean_first_fixation_duration', df_noq_h, df_noq_g)\n",
    "# label_vs_loc_mat('skip_rate', df_noq_h, df_noq_g)\n",
    "# label_vs_loc_mat('area_dwell_proportion', df_noq_h, df_noq_g)\n",
    "\n"
   ],
   "id": "e164dac8fd9345f1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def boxplot_ABCD_avg(df, stat, selected='A', h_or_g='hunters'):\n",
    "    df = df[['TRIAL_INDEX', 'participant_id', 'area_label', 'area_screen_loc', stat]].drop_duplicates().copy()\n",
    "\n",
    "    df_avg = (\n",
    "        df.groupby(['participant_id', 'area_label'])[stat]\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    sns.boxplot(\n",
    "        data=df_avg,\n",
    "        x='area_label',\n",
    "        y=stat,\n",
    "    )\n",
    "\n",
    "    plt.title(f\"{stat} distribution (averaged across screen locations) of those who chose {selected}\")\n",
    "    plt.xlabel('area_label')\n",
    "    plt.ylabel(stat)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def label_vs_loc_box_avg(metric, dfh, dfg):\n",
    "    print(\"HUNTERS\")\n",
    "    for ans in ['A', 'B', 'C', 'D']:\n",
    "        boxplot_ABCD_avg(dfh[dfh['selected_answer_label'] == ans], metric, selected=ans, h_or_g='hunters')\n",
    "\n",
    "    print(\"GATHERERS\")\n",
    "    for ans in ['A', 'B', 'C', 'D']:\n",
    "        boxplot_ABCD_avg(dfg[dfg['selected_answer_label'] == ans], metric, selected=ans, h_or_g='gatherers')\n",
    "\n",
    "\n",
    "label_vs_loc_box_avg('mean_dwell_time', df_noq_h, df_noq_g)\n"
   ],
   "id": "85581c0cc8e68a78",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def matrix_plot_first_visits_area_screen_loc(df, stat, h_or_g = 'hunters', answ ='A', start_or_end = 'first'):\n",
    "    df_selection = df[['TRIAL_INDEX', 'participant_id', stat]].drop_duplicates().copy()\n",
    "\n",
    "    df_selection['position'] = df_selection[stat].apply(lambda lst: list(range(len(lst))))\n",
    "\n",
    "    df_exploded = df_selection.explode('position')\n",
    "    df_exploded = df_exploded[df_exploded['position'].notna()]\n",
    "    df_exploded['area'] = df_exploded.apply(\n",
    "        lambda row: row[stat][int(row['position'])], axis=1\n",
    "    )\n",
    "\n",
    "    agg = df_exploded.groupby(['position', 'area']).size().reset_index(name='count')\n",
    "    pivot_table = agg.pivot(index='position', columns='area', values='count').fillna(0)\n",
    "\n",
    "    plt.figure(figsize=(8, 5))\n",
    "    sns.heatmap(pivot_table, annot=True, fmt=\"g\", cmap=\"viridis\")\n",
    "    plt.title(f\"Frequency of Area Visits by {stat}\")\n",
    "    plt.xlabel(\"Area\")\n",
    "    plt.ylabel(\"Visit Order (position)\")\n",
    "    plt.savefig(f\"new_plots/{start_or_end}_visits/{stat}_{h_or_g}_{answ}.png\")\n",
    "    plt.show()"
   ],
   "id": "bfc9bc255c3b1a73",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "A_h = df_noq_h[df_noq_h['selected_answer_label'] == 'A']\n",
    "B_h = df_noq_h[df_noq_h['selected_answer_label'] == 'B']\n",
    "C_h = df_noq_h[df_noq_h['selected_answer_label'] == 'C']\n",
    "D_h = df_noq_h[df_noq_h['selected_answer_label'] == 'D']\n",
    "\n",
    "A_g = df_noq_g[df_noq_g['selected_answer_label'] == 'A']\n",
    "B_g = df_noq_g[df_noq_g['selected_answer_label'] == 'B']\n",
    "C_g = df_noq_g[df_noq_g['selected_answer_label'] == 'C']\n",
    "D_g = df_noq_g[df_noq_g['selected_answer_label'] == 'D']\n",
    "\n",
    "data_by_ans = [A_h, B_h, C_h, D_h, A_g, B_g, C_g, D_g, A_h, B_h, C_h, D_h, A_g, B_g, C_g, D_g]\n",
    "#data_by_ans = [A_h, B_h, C_h, D_h]\n",
    "\n",
    "for data, ans in zip(data_by_ans, ['A', 'B', 'C', 'D',\n",
    "                                    'A', 'B', 'C', 'D',\n",
    "                                    'A', 'B', 'C', 'D',\n",
    "                                   'A', 'B', 'C', 'D'\n",
    "                                     ]):\n",
    "    print(f'Participants who answered {ans}:')\n",
    "    print('--------------------------------------------------------------------------')\n",
    "    print('#######First#######')\n",
    "    matrix_plot_first_visits_area_screen_loc(data, 'first_visits_area_screen_loc', h_or_g = 'hunters', answ= ans, start_or_end='first')\n",
    "    matrix_plot_first_visits_area_screen_loc(data, 'first_visits_area_label', h_or_g = 'hunters', answ=ans, start_or_end='first')\n",
    "\n",
    "    matrix_plot_first_visits_area_screen_loc(data, 'first_visits_area_screen_loc', h_or_g = 'gatherers', answ= ans, start_or_end='first')\n",
    "    matrix_plot_first_visits_area_screen_loc(data, 'first_visits_area_label', h_or_g = 'gatherers', answ=ans, start_or_end='first')\n",
    "\n",
    "\n",
    "    print('#######Last#######')\n",
    "    matrix_plot_first_visits_area_screen_loc(data, 'last_visits_area_screen_loc', h_or_g = 'hunters', answ=ans, start_or_end='last')\n",
    "    matrix_plot_first_visits_area_screen_loc(data, 'last_visits_area_label', h_or_g = 'hunters', answ=ans, start_or_end='last')\n",
    "\n",
    "    matrix_plot_first_visits_area_screen_loc(data, 'last_visits_area_screen_loc', h_or_g = 'gatherers', answ=ans, start_or_end='last')\n",
    "    matrix_plot_first_visits_area_screen_loc(data, 'last_visits_area_label', h_or_g = 'gatherers', answ=ans, start_or_end='last')\n"
   ],
   "id": "ab9e2f0014ca243c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def percentiles(df):\n",
    "    target_label = 'answer_' + df['selected_answer_label']\n",
    "\n",
    "    mask_label = df['simpl_fix_by_label'].str[-1] == target_label\n",
    "    mask_loc   = df['simpl_fix_by_loc'].str[-1] == 'answer_0'\n",
    "    mask_any   = mask_label | mask_loc\n",
    "    mask_both  = mask_label & mask_loc\n",
    "\n",
    "    print(f\"{mask_any.mean() * 100:.2f}% of rows have either last label == selected answer or last screen_loc == 'answer_0'\")\n",
    "    print(f\"{mask_both.mean() * 100:.2f}% of rows have both last label == selected answer and last screen_loc == 'answer_0'\")\n",
    "    print(f\"{mask_label.mean() * 100:.2f}% of rows have last label == selected answer\")\n",
    "    print(f\"{mask_loc.mean() * 100:.2f}% of rows have last screen_loc == 'answer_0'\")\n",
    "    print(\"----------------\")\n",
    "\n",
    "\n",
    "percentiles(df_noq_h)\n",
    "percentiles(df_noq_g)"
   ],
   "id": "a7f0e9afd973825a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Selected vs not selected",
   "id": "46f750a58f8584e7"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df_with_features_h[['TRIAL_INDEX', 'participant_id', 'is_correct', 'selected_answer_label']].drop_duplicates().copy()\n",
    "incorrect_answers = df[df['is_correct'] == 0]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(incorrect_answers['selected_answer_label'], bins=10, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Selected Answer Label for Incorrect Answers')\n",
    "plt.xlabel('Selected Answer Label')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "9a94bb01d2d46e62",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df = df_with_features_h[['TRIAL_INDEX', 'participant_id', 'is_correct', 'selected_answer_position']].drop_duplicates().copy()\n",
    "incorrect_answers = df[df['is_correct'] == 0]\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.hist(incorrect_answers['selected_answer_position'], bins=10, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Selected Answer Position for Incorrect Answers')\n",
    "plt.xlabel('Selected Answer Position')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "4a3c557f6a31593d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Fixation Sequence Visualizations",
   "id": "6d42ab015ea76e0b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_row = df_with_features_h.iloc[0]['fix_by_label']\n",
    "\n",
    "categories = {\n",
    "    \"question\": \"blue\",\n",
    "    \"answer_A\": \"green\",\n",
    "    \"answer_B\": \"orange\",\n",
    "    \"answer_C\": \"purple\",\n",
    "    \"answer_D\": \"red\",\n",
    "    \"out_of_bounds\": \"gray\"\n",
    "}\n",
    "colors = [categories[value] for value in data_row]\n",
    "\n",
    "plt.figure(figsize=(10, 2))\n",
    "plt.bar(range(len(data_row)), [1] * len(data_row), color=colors, width=1.0, edgecolor='none')\n",
    "plt.axis('off')\n",
    "\n",
    "legend_handles = [mpatches.Patch(color=color, label=label) for label, color in categories.items()]\n",
    "plt.legend(handles=legend_handles, bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Categories\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "id": "e289b9ed1657488d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "categories_label = {\n",
    "    \"question\": \"#74a9cf\",\n",
    "    \"answer_A\": \"#238b45\",\n",
    "    \"answer_B\": \"#74c476\",\n",
    "    \"answer_C\": \"#bae4b3\",\n",
    "    \"answer_D\": \"#edf8e9\",\n",
    "\n",
    "    \"A\": \"green\",\n",
    "    \"B\": \"gold\",\n",
    "    \"C\": \"darkorange\",\n",
    "    \"D\": \"red\",\n",
    "\n",
    "    \"out_of_bounds\": \"white\"\n",
    "}\n",
    "\n",
    "categories_loc = {\n",
    "    \"question\": \"#74a9cf\",\n",
    "    'answer_0': \"#ffffb2\",\n",
    "    'answer_1': \"#fecc5c\",\n",
    "    'answer_2': \"#fd8d3c\",\n",
    "    'answer_3': \"#e31a1c\",\n",
    "\n",
    "    \"A\": \"green\",\n",
    "    \"B\": \"gold\",\n",
    "    \"C\": \"darkorange\",\n",
    "    \"D\": \"red\",\n",
    "\n",
    "    \"out_of_bounds\": \"white\"\n",
    "}\n",
    "\n",
    "legend_mapping_label = {\n",
    "    \"question\": \"Question\",\n",
    "    \"answer_A\": \"Answer A\",\n",
    "    \"answer_B\": \"Answer B\",\n",
    "    \"answer_C\": \"Answer C\",\n",
    "    \"answer_D\": \"Answer D\",\n",
    "    \"out_of_bounds\": \"Unclear\",\n",
    "\n",
    "    \"A\": None,\n",
    "    \"B\": None,\n",
    "    \"C\": None,\n",
    "    \"D\": None,\n",
    "}\n",
    "\n",
    "legend_mapping_loc = {\n",
    "    \"out_of_bounds\": \"Unclear\",\n",
    "    \"question\": \"Question\",\n",
    "    \"answer_0\": \"First Answer on screen\",\n",
    "    \"answer_1\": \"Second Answer on screen\",\n",
    "    \"answer_2\": \"Third Answer on screen\",\n",
    "    \"answer_3\": \"Fourth Answer on screen\",\n",
    "\n",
    "    \"A\": None,\n",
    "    \"B\": None,\n",
    "    \"C\": None,\n",
    "    \"D\": None,\n",
    "}\n"
   ],
   "id": "7ae48542e35cbba0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def visualize_stacked_rows_with_two_labels(data_rows, categories, selected_answer_labels, additional_labels, num_rows=100, start_index=0, legend_mapping=None):\n",
    "    selected_rows = data_rows[start_index:start_index + num_rows]\n",
    "    selected_labels = selected_answer_labels[start_index:start_index + num_rows]\n",
    "    additional_labels = additional_labels[start_index:start_index + num_rows]\n",
    "\n",
    "\n",
    "    max_length = max(len(row) for row in selected_rows) + 2  # +2 to account for the labels\n",
    "\n",
    "    color_data = []\n",
    "    for row in selected_rows:\n",
    "        color_row = [categories.get(value, \"gray\") for value in row] + [\"white\"] * (max_length - len(row))\n",
    "        color_data.append(color_row)\n",
    "\n",
    "    plt.figure(figsize=(15, num_rows * 0.3))\n",
    "    for i, (color_row, label, additional_label) in enumerate(zip(color_data, selected_labels, additional_labels)):\n",
    "        plt.bar(range(max_length), [1] * max_length, color=color_row, width=1.0, edgecolor='none', bottom=i)\n",
    "        plt.text(-3.5, i + 0.5, str(additional_label), va='center', ha='right', fontsize=10, color=categories.get(additional_label, \"black\"))\n",
    "        plt.text(-1.5, i + 0.5, str(label), va='center', ha='right', fontsize=10, color=categories.get(label, \"black\"))\n",
    "\n",
    "    plt.axis('off')\n",
    "\n",
    "    if legend_mapping:\n",
    "        legend_handles = [\n",
    "            mpatches.Patch(color=categories.get(original_label, \"gray\"), label=new_label)\n",
    "            for original_label, new_label in legend_mapping.items()\n",
    "            if new_label is not None\n",
    "        ]\n",
    "    else:\n",
    "        legend_handles = [\n",
    "            mpatches.Patch(color=color, label=str(label)) for label, color in categories.items()\n",
    "        ]\n",
    "\n",
    "    plt.legend(handles=legend_handles, bbox_to_anchor=(1.05, 1), loc='upper left', title=\"Categories\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "635168a1070ad05c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_with_features_h['fix_by_label'] = df_with_features_h['fix_by_label'].apply(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "df_with_features_g['fix_by_label'] = df_with_features_g['fix_by_label'].apply(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "df_with_features_h['fix_by_loc'] = df_with_features_h['fix_by_loc'].apply(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "df_with_features_g['fix_by_loc'] = df_with_features_g['fix_by_loc'].apply(lambda x: tuple(x) if isinstance(x, list) else x)\n",
    "\n",
    "data_rows_h = df_with_features_h[['TRIAL_INDEX', 'participant_id', 'text_id', 'fix_by_label', 'fix_by_loc','selected_answer_label', 'correct_answer_position']].drop_duplicates().reset_index()\n",
    "data_rows_g = df_with_features_g[['TRIAL_INDEX', 'participant_id', 'text_id', 'fix_by_label', 'fix_by_loc','selected_answer_label', 'correct_answer_position']].drop_duplicates().reset_index()\n"
   ],
   "id": "4c7e2b8891ab442d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import random\n",
    "\n",
    "def visualize_by_id(data, by_person_or_text, fix_by, identifier=None):\n",
    "    if by_person_or_text not in ['person', 'text']:\n",
    "        raise ValueError(\"The 'by_person_or_text' parameter must be either 'person' or 'text'.\")\n",
    "\n",
    "    if fix_by not in ['label', 'loc']:\n",
    "        raise ValueError(\"The 'fix_by' parameter must be either 'label' or 'loc'.\")\n",
    "\n",
    "    if fix_by == 'label':\n",
    "        categories = categories_label\n",
    "        legend_mapping = legend_mapping_label\n",
    "        data_column = 'fix_by_label'\n",
    "\n",
    "    else:  # fix_by == 'loc'\n",
    "        categories = categories_loc\n",
    "        legend_mapping = legend_mapping_loc\n",
    "        data_column = 'fix_by_loc'\n",
    "\n",
    "    filter_column = 'participant_id' if by_person_or_text == 'person' else 'text_id'\n",
    "\n",
    "    if identifier is None:\n",
    "        available_ids = data[filter_column].dropna().unique()\n",
    "        if len(available_ids) == 0:\n",
    "            raise ValueError(f\"No valid entries found in column '{filter_column}'.\")\n",
    "        identifier = random.choice(available_ids)\n",
    "        print(f\"Randomly selected {filter_column}: {identifier}\")\n",
    "\n",
    "    subset = data[data[filter_column] == identifier]\n",
    "    if subset.empty:\n",
    "        print(f\"No data found for {filter_column} = {identifier}.\")\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        fix_data_rows = subset[data_column].tolist()\n",
    "    except KeyError:\n",
    "        raise KeyError(f\"Column '{data_column}' not found in the data.\")\n",
    "\n",
    "    selected_answer_labels = subset['selected_answer_label'].tolist()\n",
    "    additional_labels = subset['correct_answer_position'].tolist()\n",
    "\n",
    "    visualize_stacked_rows_with_two_labels(\n",
    "        fix_data_rows, categories, selected_answer_labels, additional_labels,\n",
    "        num_rows=len(fix_data_rows), legend_mapping=legend_mapping\n",
    "    )\n"
   ],
   "id": "21b0653e323be41f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_by_id(data_rows_h, by_person_or_text='person', fix_by='loc', identifier=None)",
   "id": "aef66f6efe5bac4d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# GNN",
   "id": "7519c1315f4b9222"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## prep and graph building",
   "id": "1ebc00e7286554de"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    " ## text_id = article_id + difficulty_level + article_batch + paragraph_id\n",
    "\n",
    "df_h = df_with_features_h.copy()\n"
   ],
   "id": "5c11459ff0d509af",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_h = df_h[['TRIAL_INDEX', 'participant_id', 'text_id',\n",
    "                           'IA_ID', 'IA_LABEL',\n",
    "\n",
    "                           'IA_AREA', 'IA_BOTTOM', 'IA_RIGHT', 'IA_LEFT', 'IA_TOP',\n",
    "\n",
    "                           'IA_AVERAGE_FIX_PUPIL_SIZE', 'IA_MAX_FIX_PUPIL_SIZE', 'IA_MIN_FIX_PUPIL_SIZE',\n",
    "                           'IA_DWELL_TIME', 'IA_DWELL_TIME_%',\n",
    "\n",
    "                           'IA_FIRST_FIXATION_DURATION', 'IA_FIRST_FIXATION_INDEX', 'IA_FIRST_FIXATION_PREVIOUS_FIX_IA',\n",
    "                           'IA_FIRST_FIXATION_X', 'IA_FIRST_FIXATION_Y',\n",
    "                           'IA_FIRST_FIX_PROGRESSIVE', 'IA_REGRESSION_IN_COUNT', 'IA_REGRESSION_OUT_COUNT',\n",
    "                           'IA_FIRST_RUN_DWELL_TIME',\n",
    "                           'IA_FIRST_SACCADE_AMPLITUDE', 'IA_FIRST_SACCADE_ANGLE',\n",
    "\n",
    "                           'IA_FIXATION_%', 'IA_FIXATION_COUNT',\n",
    "\n",
    "                           'IA_LAST_FIXATION_DURATION', 'IA_LAST_FIXATION_X', 'IA_LAST_FIXATION_Y',\n",
    "                           'IA_LAST_SACCADE_AMPLITUDE', 'IA_LAST_SACCADE_ANGLE',\n",
    "\n",
    "                           'IA_SKIP',\n",
    "\n",
    "                           'INTEREST_AREA_FIXATION_SEQUENCE',\n",
    "\n",
    "                           'is_correct', 'selected_answer_position', 'correct_answer_position',\n",
    "                           'area_label', 'area_screen_loc', 'selected_answer_label',\n",
    "                           'answers_order',\n",
    "\n",
    "\n",
    "                           'word_length_no_punctuation', 'wordfreq_frequency', 'subtlex_frequency', 'gpt-2_surprisal',\n",
    "                           'universal_pos', 'dependency_relation', 'entity_type', 'ptb_pos',\n",
    "                           'head_word_index', 'left_dependents_count', 'right_dependents_count', 'distance_to_head',\n",
    "\n",
    "                           'mean_dwell_time', 'mean_fixations_count', 'mean_first_fixation_duration', 'skip_rate',\n",
    "                           'area_dwell_proportion',\n",
    "                           'fix_by_label', 'fix_by_loc']]"
   ],
   "id": "5b33368db6450112",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def to_numeric(df, col, value = 0):\n",
    "    df = df.copy()\n",
    "    df[col] = df[col].replace('.', value).astype(float)\n",
    "    return df"
   ],
   "id": "4d0cc7e6311815a7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "columns_to_numerize = ['IA_AVERAGE_FIX_PUPIL_SIZE', 'IA_MAX_FIX_PUPIL_SIZE', 'IA_MIN_FIX_PUPIL_SIZE', 'IA_FIRST_FIXATION_DURATION',\n",
    "                       'IA_FIRST_FIXATION_INDEX', 'IA_FIRST_FIXATION_PREVIOUS_FIX_IA', 'IA_FIRST_FIXATION_X', 'IA_FIRST_FIXATION_Y',\n",
    "                       'IA_FIRST_RUN_DWELL_TIME', 'IA_FIRST_SACCADE_AMPLITUDE', 'IA_FIRST_SACCADE_ANGLE', 'IA_LAST_FIXATION_DURATION',\n",
    "                       'IA_LAST_FIXATION_X', 'IA_LAST_FIXATION_Y', 'IA_LAST_SACCADE_AMPLITUDE', 'IA_LAST_SACCADE_ANGLE']\n",
    "\n",
    "columns_to_numerize_not_zero = ['IA_FIRST_FIX_PROGRESSIVE', 'IA_REGRESSION_IN_COUNT','IA_REGRESSION_OUT_COUNT']\n",
    "\n",
    "for col in columns_to_numerize:\n",
    "    df_h = to_numeric(df_h, col)\n",
    "for col in columns_to_numerize_not_zero:\n",
    "    df_h = to_numeric(df_h, col, value=-1)"
   ],
   "id": "3fb8ae49cd267f9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def one_hot_encode_columns(df, columns):\n",
    "    df = df.copy()\n",
    "    for col in columns:\n",
    "        categories = sorted(df[col].dropna().unique())\n",
    "        vec_length = len(categories)\n",
    "        mapping = {cat: np.eye(vec_length)[i].tolist() for i, cat in enumerate(categories)}\n",
    "        df[col + '_encoded'] = df[col].apply(lambda x: mapping.get(x, [0.0]*vec_length))\n",
    "    return df"
   ],
   "id": "3a479e11baa8331e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "cols_to_one_hot = ['universal_pos', 'dependency_relation', 'entity_type', 'ptb_pos']\n",
    "df_h = one_hot_encode_columns(df_h, cols_to_one_hot)"
   ],
   "id": "116e0978b79912f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_trial_graph(df, feature_col_list, TRIAL_INDEX, participant_id):\n",
    "    trial_data = df[(df[\"TRIAL_INDEX\"] == TRIAL_INDEX) & (df[\"participant_id\"] == participant_id)]\n",
    "    trial_data_sorted = trial_data.sort_values(by=[\"area_screen_loc\", \"IA_ID\"])\n",
    "    trial_data_sorted_features = trial_data_sorted[feature_col_list]\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for idx, row in trial_data_sorted_features.iterrows():\n",
    "        node_id = row[\"IA_ID\"]\n",
    "        node_attributes = row.to_dict()\n",
    "        G.add_node(node_id, **node_attributes)\n",
    "\n",
    "    sorted_node_ids = list(trial_data_sorted[\"IA_ID\"])\n",
    "    for i in range(len(sorted_node_ids) - 1):\n",
    "        src = sorted_node_ids[i]\n",
    "        tgt = sorted_node_ids[i+1]\n",
    "        G.add_edge(src, tgt, type=\"sequential\")\n",
    "        G.add_edge(tgt, src, type=\"sequential\")\n",
    "\n",
    "    if \"INTEREST_AREA_FIXATION_SEQUENCE_clean\" in trial_data.columns:\n",
    "        seq_val = trial_data[\"INTEREST_AREA_FIXATION_SEQUENCE_clean\"].dropna().iloc[0]\n",
    "        seq_list = ast.literal_eval(seq_val)\n",
    "        for i in range(len(seq_list) - 1):\n",
    "            src = seq_list[i]\n",
    "            tgt = seq_list[i+1]\n",
    "            if src in G.nodes and tgt in G.nodes:\n",
    "                G.add_edge(src, tgt, type=\"saccade\")\n",
    "\n",
    "    return G\n"
   ],
   "id": "5113b9d4946d8bd0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_h_features_temp =['IA_LABEL', \"IA_ID\", 'area_label',\n",
    "                        'IA_AVERAGE_FIX_PUPIL_SIZE', 'IA_MAX_FIX_PUPIL_SIZE',\n",
    "                        'IA_MIN_FIX_PUPIL_SIZE', 'IA_FIRST_FIXATION_DURATION',\n",
    "                        'IA_FIRST_FIXATION_INDEX', 'IA_FIRST_FIXATION_PREVIOUS_FIX_IA', 'IA_FIRST_FIXATION_X', 'IA_FIRST_FIXATION_Y',\n",
    "                        'IA_FIRST_RUN_DWELL_TIME', 'IA_FIRST_SACCADE_AMPLITUDE', 'IA_FIRST_SACCADE_ANGLE', 'IA_LAST_FIXATION_DURATION',\n",
    "                        'IA_LAST_FIXATION_X', 'IA_LAST_FIXATION_Y', 'IA_LAST_SACCADE_AMPLITUDE', 'IA_LAST_SACCADE_ANGLE','IA_FIRST_FIX_PROGRESSIVE',\n",
    "                        'IA_REGRESSION_IN_COUNT','IA_REGRESSION_OUT_COUNT',\n",
    "\n",
    "                        'word_length_no_punctuation', 'wordfreq_frequency', 'subtlex_frequency', 'gpt-2_surprisal',\n",
    "                        'head_word_index', 'left_dependents_count', 'right_dependents_count', 'distance_to_head',\n",
    "\n",
    "                        'universal_pos_encoded', 'dependency_relation_encoded', 'entity_type_encoded', 'ptb_pos_encoded'\n",
    "\n",
    "                     ]"
   ],
   "id": "a488f062e0d4326e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "graph = create_trial_graph(df_h, df_h_features_temp, TRIAL_INDEX=7, participant_id='l42_2070')",
   "id": "91f0a5cd08762016",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## defining the network",
   "id": "62917f49f4953910"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GINConv, global_mean_pool\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch_geometric.utils import from_networkx\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.data import Data\n"
   ],
   "id": "907da55e81bd66e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class AnswerPredictorGIN(torch.nn.Module):\n",
    "    def __init__(self, num_node_features, hidden_dim=64, num_classes=4):\n",
    "        super(AnswerPredictorGIN, self).__init__()\n",
    "        nn1 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(num_node_features, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.conv1 = GINConv(nn1)\n",
    "\n",
    "        nn2 = torch.nn.Sequential(\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(hidden_dim, hidden_dim)\n",
    "        )\n",
    "        self.conv2 = GINConv(nn2)\n",
    "\n",
    "        self.fc = torch.nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = global_mean_pool(x, batch)\n",
    "        x = self.fc(x)\n",
    "        return F.log_softmax(x, dim=1)"
   ],
   "id": "fb94f797ae7ed90c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def split_trials(df, test_size=0.2, random_state=42):\n",
    "    df = df.copy()\n",
    "    df['trial_uid'] = df['TRIAL_INDEX'].astype(str) + '_' + df['participant_id'].astype(str)\n",
    "    unique_trials = df['trial_uid'].unique()\n",
    "    train_trials, test_trials = train_test_split(unique_trials, test_size=test_size, random_state=random_state)\n",
    "    df_train = df[df['trial_uid'].isin(train_trials)]\n",
    "    df_test = df[df['trial_uid'].isin(test_trials)]\n",
    "    return df_train, df_test"
   ],
   "id": "33dbaaecf7e322e6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_trial_data_old(df, feature_col_list, TRIAL_INDEX, participant_id):\n",
    "    trial_data = df[(df[\"TRIAL_INDEX\"] == TRIAL_INDEX) & (df[\"participant_id\"] == participant_id)]\n",
    "    trial_data_sorted = trial_data.sort_values(by=[\"area_screen_loc\", \"IA_ID\"])\n",
    "\n",
    "    trial_data_sorted_features = trial_data_sorted.copy()\n",
    "\n",
    "    G = nx.DiGraph()\n",
    "\n",
    "    for idx, row in trial_data_sorted_features.iterrows():\n",
    "        node_id = row[\"IA_ID\"]\n",
    "        node_attributes = {col: row[col] for col in feature_col_list}\n",
    "        G.add_node(node_id, **node_attributes)\n",
    "\n",
    "    sorted_node_ids = list(trial_data_sorted[\"IA_ID\"])\n",
    "    for i in range(len(sorted_node_ids) - 1):\n",
    "        src = sorted_node_ids[i]\n",
    "        tgt = sorted_node_ids[i+1]\n",
    "        G.add_edge(src, tgt, type=\"sequential\")\n",
    "\n",
    "    if \"INTEREST_AREA_FIXATION_SEQUENCE_clean\" in trial_data.columns:\n",
    "        seq_val = trial_data[\"INTEREST_AREA_FIXATION_SEQUENCE_clean\"].dropna().iloc[0]\n",
    "        seq_list = ast.literal_eval(seq_val)\n",
    "        for i in range(len(seq_list) - 1):\n",
    "            src = seq_list[i]\n",
    "            tgt = seq_list[i+1]\n",
    "            if src in G.nodes and tgt in G.nodes:\n",
    "                G.add_edge(src, tgt, type=\"saccade\")\n",
    "\n",
    "    data = from_networkx(G)\n",
    "\n",
    "    node_order = list(G.nodes)\n",
    "    node_features = []\n",
    "    for node in node_order:\n",
    "        feat = [G.nodes[node].get(col, 0) for col in feature_col_list]\n",
    "        node_features.append(feat)\n",
    "    data.x = torch.tensor(node_features, dtype=torch.float)\n",
    "\n",
    "    data.x = torch.nan_to_num(data.x, nan=-1.0, posinf=1e9, neginf=-1e9)\n",
    "\n",
    "    label = trial_data_sorted[\"selected_answer_position\"].iloc[0]\n",
    "    data.y = torch.tensor([label], dtype=torch.long)\n",
    "\n",
    "    data.trial_uid = f\"{TRIAL_INDEX}_{participant_id}\"\n",
    "\n",
    "    return data"
   ],
   "id": "e2e1ed1b6e7963bb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def create_trial_data(df, feature_col_list, TRIAL_INDEX, participant_id):\n",
    "    trial_data = df[(df[\"TRIAL_INDEX\"] == TRIAL_INDEX) & (df[\"participant_id\"] == participant_id)]\n",
    "    trial_data_sorted = trial_data.sort_values(by=[\"area_screen_loc\", \"IA_ID\"]).reset_index(drop=True)\n",
    "\n",
    "    node_ids = list(trial_data_sorted[\"IA_ID\"])\n",
    "    node_features = []\n",
    "    for _, row in trial_data_sorted.iterrows():\n",
    "        features = [row[col] for col in feature_col_list]\n",
    "        node_features.append(features)\n",
    "    x = torch.tensor(node_features, dtype=torch.float)\n",
    "    x = torch.nan_to_num(x, nan=-1.0, posinf=1e9, neginf=-1e9)\n",
    "\n",
    "    node_id_to_idx = {node_id: idx for idx, node_id in enumerate(node_ids)}\n",
    "\n",
    "    edges = []\n",
    "    for i in range(len(node_ids) - 1):\n",
    "        edges.append([i, i + 1])\n",
    "        edges.append([i + 1, i])\n",
    "\n",
    "    if \"INTEREST_AREA_FIXATION_SEQUENCE_clean\" in trial_data.columns:\n",
    "        seq_val = trial_data[\"INTEREST_AREA_FIXATION_SEQUENCE_clean\"].dropna().iloc[0]\n",
    "        seq_list = ast.literal_eval(seq_val)\n",
    "        for i in range(len(seq_list) - 1):\n",
    "            src, tgt = seq_list[i], seq_list[i + 1]\n",
    "            if src in node_id_to_idx and tgt in node_id_to_idx:\n",
    "                edges.append([node_id_to_idx[src], node_id_to_idx[tgt]])\n",
    "\n",
    "    if edges:\n",
    "        edge_index = torch.tensor(edges, dtype=torch.long).t().contiguous()\n",
    "    else:\n",
    "        edge_index = torch.empty((2, 0), dtype=torch.long)\n",
    "\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    label = trial_data_sorted[\"selected_answer_position\"].iloc[0]\n",
    "    data.y = torch.tensor([label], dtype=torch.long)\n",
    "    data.trial_uid = f\"{TRIAL_INDEX}_{participant_id}\"\n",
    "\n",
    "    return data"
   ],
   "id": "5781fa1e82232449",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def build_graphs(df, feature_col_list):\n",
    "    graphs = []\n",
    "    for uid, group in df.groupby(\"trial_uid\"):\n",
    "        TRIAL_INDEX = group[\"TRIAL_INDEX\"].iloc[0]\n",
    "        participant_id = group[\"participant_id\"].iloc[0]\n",
    "        data = create_trial_data(df, feature_col_list, TRIAL_INDEX, participant_id)\n",
    "        graphs.append(data)\n",
    "    return graphs"
   ],
   "id": "367ca5dc4073e527",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "h_features_list =[\n",
    "                        'IA_AVERAGE_FIX_PUPIL_SIZE', 'IA_MAX_FIX_PUPIL_SIZE',\n",
    "                        'IA_MIN_FIX_PUPIL_SIZE', 'IA_FIRST_FIXATION_DURATION',\n",
    "                        'IA_FIRST_FIXATION_INDEX', 'IA_FIRST_FIXATION_PREVIOUS_FIX_IA', 'IA_FIRST_FIXATION_X', 'IA_FIRST_FIXATION_Y',\n",
    "                        'IA_FIRST_RUN_DWELL_TIME', 'IA_FIRST_SACCADE_AMPLITUDE', 'IA_FIRST_SACCADE_ANGLE', 'IA_LAST_FIXATION_DURATION',\n",
    "                        'IA_LAST_FIXATION_X', 'IA_LAST_FIXATION_Y', 'IA_LAST_SACCADE_AMPLITUDE',\n",
    "                        'IA_LAST_SACCADE_ANGLE','IA_FIRST_FIX_PROGRESSIVE',\n",
    "                        'IA_REGRESSION_IN_COUNT','IA_REGRESSION_OUT_COUNT',\n",
    "\n",
    "                        'word_length_no_punctuation', 'wordfreq_frequency', 'subtlex_frequency', 'gpt-2_surprisal',\n",
    "                        'head_word_index', 'left_dependents_count', 'right_dependents_count', 'distance_to_head',\n",
    "\n",
    "                        #'universal_pos_encoded', 'dependency_relation_encoded', 'entity_type_encoded', 'ptb_pos_encoded'\n",
    "                     ]"
   ],
   "id": "79b773fc07b1dd32",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "#try with no eyemovements",
   "id": "d43bd62463517fc4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "na_rows = df_h[df_h[h_features_list].isna().any(axis=1)]\n",
    "na_pairs = na_rows[['TRIAL_INDEX', 'participant_id']].drop_duplicates()\n",
    "\n",
    "df_clean = df_h.merge(\n",
    "    na_pairs,\n",
    "    on=['TRIAL_INDEX', 'participant_id'],\n",
    "    how='left',\n",
    "    indicator=True\n",
    ")\n",
    "df_clean = df_clean[df_clean['_merge'] == 'left_only'].drop(columns=['_merge'])"
   ],
   "id": "3490da89fc50645a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "df_train, df_test = split_trials(df_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "train_graphs = build_graphs(df_train, h_features_list)\n",
    "test_graphs = build_graphs(df_test, h_features_list)\n",
    "\n",
    "train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_graphs, batch_size=32, shuffle=False)"
   ],
   "id": "c1b0bcf89ca91de1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "num_node_features = train_graphs[0].x.shape[1]\n",
    "model = AnswerPredictorGIN(num_node_features=num_node_features)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = torch.nn.NLLLoss()"
   ],
   "id": "2d551ae2cde0504f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = criterion(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * data.num_graphs\n",
    "    return total_loss / len(train_loader.dataset)\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)\n",
    "        correct += int((pred == data.y).sum())\n",
    "    return correct / len(loader.dataset)"
   ],
   "id": "c61ae8997f84927f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for epoch in range(1, 201):\n",
    "    loss = train()\n",
    "    train_acc = test(train_loader)\n",
    "    test_acc = test(test_loader)\n",
    "    print(f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
    "\n",
    "\n",
    "# no eyes -\n",
    "#           Epoch: 195, Loss: 1.1463, Train Acc: 0.4803, Test Acc: 0.4071\n",
    "#           Epoch: 196, Loss: 1.1383, Train Acc: 0.4790, Test Acc: 0.3989\n",
    "#           Epoch: 197, Loss: 1.1369, Train Acc: 0.4982, Test Acc: 0.3999\n",
    "#           Epoch: 198, Loss: 1.1375, Train Acc: 0.4967, Test Acc: 0.4081\n",
    "#           Epoch: 199, Loss: 1.1362, Train Acc: 0.4985, Test Acc: 0.3886\n",
    "#           Epoch: 200, Loss: 1.1297, Train Acc: 0.4869, Test Acc: 0.4189\n",
    "\n",
    "\n",
    "# yes eyes -\n",
    "#             Epoch: 195, Loss: 0.7072, Train Acc: 0.7310, Test Acc: 0.5214\n",
    "#             Epoch: 196, Loss: 0.7168, Train Acc: 0.7236, Test Acc: 0.5342\n",
    "#             Epoch: 197, Loss: 0.7112, Train Acc: 0.7330, Test Acc: 0.5085\n",
    "#             Epoch: 198, Loss: 0.6959, Train Acc: 0.7270, Test Acc: 0.5147\n",
    "#             Epoch: 199, Loss: 0.6964, Train Acc: 0.7362, Test Acc: 0.5229\n",
    "#             Epoch: 200, Loss: 0.7003, Train Acc: 0.7542, Test Acc: 0.5373\n"
   ],
   "id": "3cfaec668922c989",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# visualise a graph",
   "id": "90f398bd98219abe"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def grid_layout(G):\n",
    "    nodes = list(G.nodes())\n",
    "    n = len(nodes)\n",
    "    if n == 0:\n",
    "        return {}\n",
    "\n",
    "    cols = math.ceil(math.sqrt(n))\n",
    "    rows = math.ceil(n / cols)\n",
    "\n",
    "    pos = {}\n",
    "    for i, node in enumerate(nodes):\n",
    "        row = i // cols\n",
    "        col = i % cols\n",
    "        pos[node] = (col, -row)\n",
    "    return pos\n",
    "\n",
    "def visualize_graph(G):\n",
    "    pos = grid_layout(G)\n",
    "\n",
    "    labels = {node: data.get('IA_LABEL', str(node)) for node, data in G.nodes(data=True)}\n",
    "\n",
    "    area_color_map = {\n",
    "        \"question\": \"#74a9cf\",\n",
    "        \"answer_A\": \"#238b45\",\n",
    "        \"answer_B\": \"#74c476\",\n",
    "        \"answer_C\": \"#bae4b3\",\n",
    "        \"answer_D\": \"#edf8e9\",\n",
    "    }\n",
    "\n",
    "    node_colors = []\n",
    "    for node, data in G.nodes(data=True):\n",
    "        area = data.get('area_label', 'question')\n",
    "        node_colors.append(area_color_map.get(area, 'grey'))\n",
    "\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=500)\n",
    "\n",
    "    seq_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get('type') == 'sequential']\n",
    "    sac_edges = [(u, v) for u, v, d in G.edges(data=True) if d.get('type') == 'saccade']\n",
    "\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=seq_edges, edge_color='green', arrows=True)\n",
    "    nx.draw_networkx_edges(G, pos, edgelist=sac_edges, edge_color='red', style='dashed', arrows=True)\n",
    "\n",
    "    nx.draw_networkx_labels(G, pos, labels=labels, font_size=10)\n",
    "\n",
    "    legend_elements = [\n",
    "        Line2D([0], [0], marker='o', color='w', label='Sequential Edge',\n",
    "               markerfacecolor='green', markersize=10),\n",
    "        Line2D([0], [0], color='red', lw=2, linestyle='dashed', label='Saccade Edge')\n",
    "    ]\n",
    "\n",
    "    for area, color in area_color_map.items():\n",
    "        patch = mpatches.Patch(color=color, label=area)\n",
    "        legend_elements.append(patch)\n",
    "\n",
    "    plt.legend(handles=legend_elements, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(\"Graph Visualization on a Rectangular Grid\")\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n"
   ],
   "id": "1e67ab1e0c77ecc1",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "visualize_graph(graph)",
   "id": "ce428487dfd4a0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "acdf70d500451004",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
